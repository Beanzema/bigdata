{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 구성:Series, DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 데이터 분할:train, test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 분류 Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 분류 Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 분류 Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# 분류 NN (MLPClassifier)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# 분류 KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# 로지스틱 회귀\n",
    "from statsmodels.api import Logit\n",
    "# 최적 모델, 파라미터 탐색\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 분류모델 평가 함수\n",
    "from sklearn.metrics import accuracy_score, f1_score \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 모델 성능 평가: Precision, Recall, F1 Score, ROC Curve, AUC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "# 샘플링 : Over-sampling 등\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# Check the Frequency of Variable\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff603d",
   "metadata": {},
   "source": [
    "# 매번 분류모델 제작하고 비교하는 코드 짜기 번거로워 만든 분류 종합선물세트\n",
    "    일단 데이터 아래 세번째 형태에 맞게 해서 순차적으로 다 실행하도록. 그러면 모델별 그래프 합쳐져서 최종적으로 다같이 비교할 수 있도록 막대그래프 시각화돼 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff02af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트 적용, 차트에서 음수 표시\n",
    "matplotlib.rc('font', family='NanumGothic')\n",
    "matplotlib.rc(\"axes\", unicode_minus = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954452aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_data_layout(v_data):\n",
    "    print(\"Data 구조:\", v_data.shape)\n",
    "    print()\n",
    "    print(\"변수 : \", v_data.columns)\n",
    "    print()\n",
    "    #print(v_data.head()) <- Text format... 식별 불편\n",
    "    # v_data.head()  <- 직접 적용 안됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5393d04",
   "metadata": {},
   "source": [
    "# df_raw를 독립변수와 종속변수만 있는 셋으로 정리하고, 아래 순차적으로 진행해주면 됨. 결측치는 당연히 미리 제거해둬야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7171b740",
   "metadata": {},
   "source": [
    "    SCALE은 아래 전부 출하여부 열로 바꿔야하는거 까먹지말고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies: 데이터의 문자형 변수에 대한 더미변수 생성 \n",
    "df_raw_dummy = pd.get_dummies(df_raw)\n",
    "\n",
    "# 설명변수, 목표변수 데이터 지정\n",
    "df_raw_x = df_raw_dummy.drop([\"SCALE\"], axis = 1, inplace = False)\n",
    "df_raw_y = df_raw_dummy[\"SCALE\"] \n",
    "\n",
    "# train_test_split(X: 설명변수 데이터, Y: 목표변수 데이터, test_size = test 데이터 비율, random_state: 랜덤)\n",
    "df_train_x, df_test_x, df_train_y, df_test_y = train_test_split(df_raw_x, # 설명변수 데이터\n",
    "                                                                df_raw_y, # 목표변수 데이터\n",
    "                                                                test_size = 0.3, # test 데이터의 비율\n",
    "                                                                random_state = 1234)  # random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab619db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies: 데이터의 문자형 변수에 대한 더미변수 생성 \n",
    "df_raw_dummy = pd.get_dummies(df_raw)\n",
    "\n",
    "# 설명변수, 목표변수 데이터 지정\n",
    "df_raw_x = df_raw_dummy.drop([\"SCALE\"], axis = 1, inplace = False)\n",
    "df_raw_y = df_raw_dummy[\"SCALE\"] \n",
    "\n",
    "# train_test_split(X: 설명변수 데이터, Y: 목표변수 데이터, test_size = test 데이터 비율, random_state: 랜덤)\n",
    "df_train_x, df_test_x, df_train_y, df_test_y = train_test_split(df_raw_x, # 설명변수 데이터\n",
    "                                                                df_raw_y, # 목표변수 데이터\n",
    "                                                                test_size = 0.3, # test 데이터의 비율\n",
    "                                                                random_state = 1234)  # random state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbbe3de",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀(1)_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split(데이터, test_size = test 데이터 비율, random_state: 랜덤)\n",
    "df_train, df_test = train_test_split(df_raw, # 데이터\n",
    "                                     test_size = 0.3, # test 데이터의 비율\n",
    "                                     random_state = 1234)  # random state\n",
    "\n",
    "print(\"train data size : {}\".format(df_train.shape))\n",
    "print(\"test data size : {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 귀차니스트를 위한 로지스틱 회귀모델 변수랑 + 타자 안치기 용.\n",
    "# 종속변수 왼쪽빼는거랑 ~ 하는거 잊지 말고.\n",
    "'+'.join(df_raw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b88ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = Logit.from_formula(\"SCALE~ROLLING_TEMP_T5 + FUR_SZ_TEMP + ROLLING_DESCALING\"\"\", df_train)\n",
    "\n",
    "# 적합\n",
    "log_result = log_model.fit()\n",
    "\n",
    "# 결과 출력\n",
    "print(log_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터 예측\n",
    "y_pred_train = log_result.predict(df_train)\n",
    "# 0과 1의 값을 가진 class로 변환\n",
    "y_pred_train_class = (y_pred_train > 0.53).astype(int)\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion_matrix(df_train[\"SCALE\"],y_pred_train_class)),\"\\n\")\n",
    "\n",
    "# test 데이터 예측\n",
    "y_pred_test = log_result.predict(df_test)\n",
    "# 0과 1의 값을 가진 class로 변환\n",
    "y_pred_test_class = (y_pred_test > 0.53).astype(int)\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion_matrix(df_test[\"SCALE\"],y_pred_test_class)),\"\\n\")\n",
    "\n",
    "# 실제 train 데이터와 예측 결과 비교\n",
    "print(\"Train 예측/분류 결과\")\n",
    "print(\"Accuracy: {0:.3f}\\n\".format(accuracy_score(df_train[\"SCALE\"], y_pred_train_class)))\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion_matrix(df_train[\"SCALE\"],y_pred_train_class)),\"\\n\")\n",
    "print(classification_report(df_train[\"SCALE\"], y_pred_train_class, digits=3))\n",
    "\n",
    "# 실제 train 데이터와 예측 결과 비교\n",
    "print(\"Test 예측/분류 결과\")\n",
    "print(\"Accuracy: {0:.3f}\\n\".format(accuracy_score(df_test[\"SCALE\"], y_pred_test_class)))\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion_matrix(df_test[\"SCALE\"],y_pred_test_class)),\"\\n\")\n",
    "print(classification_report(df_test[\"SCALE\"], y_pred_test_class, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c39871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0과 1의 값을 가진 class로 변환: 임계값 변경-> 예측 빈도 달라짐\n",
    "y_pred_test_class = (y_pred_test > 0.6).astype(int)\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion_matrix(df_test[\"SCALE\"],y_pred_test_class)),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eeb2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 train 데이터와 예측 결과 비교\n",
    "print(\"Train 예측/분류 결과\")\n",
    "print(\"Accuracy: {0:.3f}\\n\".format(accuracy_score(df_train[\"SCALE\"], y_pred_train_class)))\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion_matrix(df_train[\"SCALE\"],y_pred_train_class)),\"\\n\")\n",
    "print(classification_report(df_train[\"SCALE\"], y_pred_train_class, digits=3))\n",
    "\n",
    "# 실제 train 데이터와 예측 결과 비교\n",
    "print(\"Test 예측/분류 결과\")\n",
    "print(\"Accuracy: {0:.3f}\\n\".format(accuracy_score(df_test[\"SCALE\"], y_pred_test_class)))\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion_matrix(df_test[\"SCALE\"],y_pred_test_class)),\"\\n\")\n",
    "print(classification_report(df_test[\"SCALE\"], y_pred_test_class, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1eae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "for i in range(1,10):\n",
    "    j = i*0.1\n",
    "    # 0과 1의 값을 가진 class로 변환\n",
    "    y_pred_train_class = (y_pred_train > j).astype(int)\n",
    "    y_pred_test_class = (y_pred_test > j).astype(int)\n",
    "    train_score = accuracy_score(df_train[\"SCALE\"], y_pred_train_class)\n",
    "    test_score = accuracy_score(df_test[\"SCALE\"], y_pred_test_class)\n",
    "    train_list.append(train_score)\n",
    "    test_list.append(test_score)\n",
    "\n",
    "df = pd.DataFrame({'train': train_list, 'test': test_list})\n",
    "\n",
    "index = [0.01*i for i in range(1,100)]\n",
    "\n",
    "# 모델 정확도 그래프 확인\n",
    "plt.plot(index, train_list, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(index, test_list, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.xlabel(\"임계값\"); plt.ylabel(\"accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14678259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수 중요도\n",
    "df_logistic_coef = pd.DataFrame({\"Coef\": log_result.params.values[1:]}, index = log_model.exog_names[1:])\n",
    "df_logistic_coef.plot.barh(y = \"Coef\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c096a",
   "metadata": {},
   "source": [
    "# 의사결정 나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sampling 설정\n",
    "sm = SMOTE(sampling_strategy='auto')\n",
    "\n",
    "# train데이터를 이용한 Over-sampling\n",
    "x_resampled, y_resampled = sm.fit_resample(df_train_x,df_train_y)\n",
    "\n",
    "# 결과 확인\n",
    "print('Over-Sampling 전:\\n',df_train_y.value_counts(),\"\\n\")\n",
    "print('Over-Sampling 후 Train X: {}'.format(x_resampled.shape))\n",
    "print('Over-Sampling 후 Train Y: {} \\n'.format(y_resampled.shape))\n",
    "\n",
    "print(\"Over-Sampling 후 '1':{}\".format(sum(y_resampled==1)))\n",
    "print(\"Over-Sampling 후 '0':{}\".format(sum(y_resampled==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목표변수 빈도 확인\n",
    "print(df_raw.value_counts([\"SCALE\"]),\"\\n\")\n",
    "# print(df_raw[\"BAD\"].value_counts(), \"\\n\")\n",
    "print(\"불량 비율  \", df_raw.value_counts(df_raw[\"SCALE\"]==1)/len(df_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시나 그리드서치 돌릴지도 모르는 너를 위해\n",
    "para_depth = [depth for depth in range(1, 7)]\n",
    "para_split = [n_split * 1 for n_split in range(1, 11)]\n",
    "para_leaf = [n_leaf * 1 for n_leaf in range(1, 21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb92d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DecisionTreeClassifier(random_state=1234)\n",
    "# 구하고자 하는 parameter와 범위\n",
    "param_grid = {\"max_depth\": para_depth, \"min_samples_split\": para_split,\n",
    "              \"min_samples_leaf\": para_leaf}\n",
    "# 정확도가 높은 최적 parameter 찾기\n",
    "grid_dt = GridSearchCV(estimator, param_grid, scoring=\"accuracy\", n_jobs = -1)\n",
    "grid_dt.fit(x_resampled, y_resampled)\n",
    "\n",
    "print(\"best estimator model: \\n{}\".format(grid_dt.best_estimator_))\n",
    "print(\"\\nbest parameter: \\n{}\".format(grid_dt.best_params_))\n",
    "print(\"\\nbest score: \\n{}\".format(grid_dt.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_graphviz: 나무 구조 생성 및 저장 \n",
    "from sklearn.tree import export_graphviz\n",
    "# graphviz : 나무 구조 시각화  (.dot 확장자 파일 불러오기 등)\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd2abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수명 저장\n",
    "v_feature_name = df_train_x.columns\n",
    "\n",
    "tree_low = DecisionTreeClassifier(max_depth= 10, min_samples_leaf= 10, min_samples_split= 8, random_state=1234)\n",
    "tree_low.fit(df_train_x, df_train_y)\n",
    "\n",
    "# 트리 모델을 tree_low.dot 파일로 저장. (목표변수, 0: Good, 1: Bad)\n",
    "export_graphviz(tree_low, out_file=\"tree_low.dot\", class_names = [\"양품\", \"불량\"], # 목표변수 값이 숫자-> Label 직접 지정\n",
    "                # class_names = tree_low.classes_,원래 목표변수 값이 법주형 -> 모델 keyword 사용           \n",
    "                feature_names = v_feature_name, impurity = True, filled = True)\n",
    "# graphviz를 이용해 트리 모델 시각화\n",
    "with open(\"tree_low.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3cb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이거 하면 현재 폴더에 DT 이미지 파일 저장됨. 그거 공유해주면 됨.\n",
    "graphviz.Source(dot_graph).render('tree', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e06708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "y_pred = grid_dt.predict(df_test_x)\n",
    "print(\"Accuracy: {0:.3f}\\n\".format(grid_dt.score(df_test_x, df_test_y)))\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))\n",
    "\n",
    "# 목표변수의 빈도 불균형 : f1 score로 모델 평가 \n",
    "print(classification_report(df_test_y, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.feature_importances_로 설명변수 중요도 확인 및 테이블로 저장\n",
    "df_importance = pd.DataFrame()\n",
    "df_importance[\"Feature\"] = v_feature_name\n",
    "df_importance[\"Importance\"] = dt_final.feature_importances_\n",
    "\n",
    "# df_feature_importance의 테이블을 중요도별로 정렬\n",
    "df_importance.sort_values(\"Importance\", ascending=False, inplace = True)\n",
    "df_temp = df_importance.round(3).head(6)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수 중요도 그래프\n",
    "# sort_values : 중요도가 높은 변수를 상위에 그림. \n",
    "df_temp.sort_values(\"Importance\", ascending=True, inplace = True)\n",
    "coordinates = range(len(df_temp))\n",
    "plt.barh(y = coordinates, width = df_temp[\"Importance\"])\n",
    "plt.yticks(coordinates, df_temp[\"Feature\"])\n",
    "plt.xlabel(\"설명변수 중요도\")\n",
    "plt.ylabel(\"설명변수\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af073bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve 그리기, label에 auc 표시(소수점 2자리)\n",
    "plt.plot(fpr, tpr, label= \"AUC = %0.5f\"% roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel(\"TPR\"); plt.xlabel(\"FPR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a3e76",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab233284",
   "metadata": {},
   "source": [
    "    그리드서치 최적값 범위는 DT에서 얼추 찾고 그 언저리로 패러미터 범위 설정해줘라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77bbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimatos: 트리 수 변경: 1~150\n",
    "para_n_tree = [n_tree * 10 for n_tree in range(1, 11)]\n",
    "# max_depth: 최대 깊이 변경\n",
    "para_depth = [depth for depth in range(2, 8)]\n",
    "# min_samples_split: 분할하기 위한 노드의 최소 샘플 수 \n",
    "para_split = [n_split * 2 for n_split in range(1, 21)]\n",
    "# min_samples_leaf: 잎사귀 수 제한\n",
    "para_leaf = [n_leaf * 1 for n_leaf in range(2, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63540a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_leaf = [n_leaf * 1 for n_leaf in range(2, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aeb2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier(n_estimators=100,random_state=1234)\n",
    "# 구하고자 하는 parameter와 범위\n",
    "param_grid = {\"max_depth\": para_depth,\n",
    "              \"min_samples_leaf\": para_leaf,\n",
    "             'min_samples_split': para_split}\n",
    "# 정확도가 높은 최적 parameter 찾기\n",
    "grid_rf = GridSearchCV(estimator, param_grid, scoring=\"accuracy\", n_jobs = -1)\n",
    "grid_rf.fit(x_resampled, y_resampled)\n",
    "print(\"best estimator model: \\n{}\".format(grid_rf.best_estimator_))\n",
    "print(\"\\nbest parameter: \\n{}\".format(grid_rf.best_params_))\n",
    "print(\"\\nbest score: \\n{}\".format(grid_rf.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "y_pred = grid_rf.predict(df_test_x)\n",
    "print(\"Accuracy: {0:.3f}\\n\".format(grid_rf.score(df_test_x, df_test_y)))\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))\n",
    "\n",
    "# 목표변수의 빈도 불균형 : f1 score로 모델 평가 \n",
    "print(classification_report(df_test_y, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f8991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_rf.score(df_train_x, df_train_y))\n",
    "grid_rf.score(df_test_x, df_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e025a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final = RandomForestClassifier(max_depth=13, min_samples_leaf=2, min_samples_split=6,\n",
    "                       random_state=1234)\n",
    "\n",
    "rf_final.fit(x_resampled, y_resampled)\n",
    "\n",
    "# tree.feature_importances_로 설명변수 중요도 확인 및 테이블로 저장\n",
    "df_importance = pd.DataFrame()\n",
    "df_importance[\"Feature\"] = v_feature_name\n",
    "df_importance[\"Importance\"] = rf_final.feature_importances_\n",
    "\n",
    "# df_feature_importance의 테이블을 중요도별로 정렬\n",
    "df_importance.sort_values(\"Importance\", ascending=False, inplace = True)\n",
    "df_temp = df_importance.round(3).head(6)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e097a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수 중요도 그래프\n",
    "# sort_values : 중요도가 높은 변수를 상위에 그림. \n",
    "df_temp.sort_values(\"Importance\", ascending=True, inplace = True)\n",
    "coordinates = range(len(df_temp))\n",
    "plt.barh(y = coordinates, width = df_temp[\"Importance\"])\n",
    "plt.yticks(coordinates, df_temp[\"Feature\"])\n",
    "plt.xlabel(\"설명변수 중요도\")\n",
    "plt.ylabel(\"설명변수\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4afc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve 그리기, label에 auc 표시(소수점 2자리)\n",
    "plt.plot(fpr, tpr, label= \"AUC = %0.5f\"% roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel(\"TPR\"); plt.xlabel(\"FPR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897adf0",
   "metadata": {},
   "source": [
    "# 그래디언트 부스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f69f08",
   "metadata": {},
   "source": [
    "### 아래 패러미터 범위 고려 DT에서 해보고 고민 조금만 해서 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da310a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate 학습률 변경: 0.1 기준\n",
    "para_lr = [lr * 0.01 for lr in range(7, 14)]\n",
    "# n_estimatos: 트리 수 변경: 110 기준\n",
    "para_n_tree = [n_tree * 1 for n_tree in range(85, 95)]\n",
    "# max_depth: 최대 깊이 변경: 3 기준\n",
    "para_depth = [depth for depth in range(2, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dfa46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GradientBoostingClassifier(n_estimators=110, max_depth = 3\n",
    "                                       ,learning_rate = 0.1 , random_state=1234)\n",
    "# 구하고자 하는 parameter와 범위\n",
    "param_grid = {\"min_samples_leaf\": para_leaf, \"learning_rate\": para_lr}\n",
    "# 정확도가 높은 최적 parameter 찾기\n",
    "grid_gb = GridSearchCV(estimator, param_grid, scoring=\"accuracy\", n_jobs = -1)\n",
    "grid_gb.fit(x_resampled, y_resampled)\n",
    "print(\"best estimator model: \\n{}\".format(grid_gb.best_estimator_))\n",
    "print(\"\\nbest parameter: \\n{}\".format(grid_gb.best_params_))\n",
    "print(\"\\nbest score: \\n{}\".format(grid_gb.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69977fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_gb.score(df_train_x, df_train_y))\n",
    "print(grid_gb.score(df_test_x, df_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93913ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_final = GradientBoostingClassifier(min_samples_leaf=4, n_estimators=110,\n",
    "                           random_state=1234)\n",
    "\n",
    "gb_final.fit(x_resampled, y_resampled)\n",
    "\n",
    "# tree.feature_importances_로 설명변수 중요도 확인 및 테이블로 저장\n",
    "df_importance = pd.DataFrame()\n",
    "df_importance[\"Feature\"] = v_feature_name\n",
    "df_importance[\"Importance\"] = gb_final.feature_importances_\n",
    "\n",
    "# df_feature_importance의 테이블을 중요도별로 정렬\n",
    "df_importance.sort_values(\"Importance\", ascending=False, inplace = True)\n",
    "df_temp = df_importance.round(3).head(6)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8085a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수 중요도 그래프\n",
    "# sort_values : 중요도가 높은 변수를 상위에 그림. \n",
    "df_temp.sort_values(\"Importance\", ascending=True, inplace = True)\n",
    "coordinates = range(len(df_temp))\n",
    "plt.barh(y = coordinates, width = df_temp[\"Importance\"])\n",
    "plt.yticks(coordinates, df_temp[\"Feature\"])\n",
    "plt.xlabel(\"설명변수 중요도\")\n",
    "plt.ylabel(\"설명변수\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve 그리기, label에 auc 표시(소수점 2자리)\n",
    "plt.plot(fpr, tpr, label= \"AUC = %0.5f\"% roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel(\"TPR\"); plt.xlabel(\"FPR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621933cc",
   "metadata": {},
   "source": [
    "# XG 부스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost 패키지 불러오기 \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 변수 중요도 확인: F1 점수 기준\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# 분류모델 평가 함수\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 분류모델 통합 평가: 혼동행렬, 정확도, 정밀도, 재현율, F1, AUC 등\n",
    "def eval_class_model(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    print('오차행렬:\\n', confusion, '\\n')\n",
    "    print('정확도: {:.4f}'.format(accuracy))\n",
    "    print('정밀도: {:.4f}'.format(precision))\n",
    "    print('재현율: {:.4f}'.format(recall))\n",
    "    print('F1    : {:.4f}'.format(F1))\n",
    "    print('AUC   : {:.4f}'.format(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn XGBoost 모델의 조기 중단 : fit( )에 파라미터 입력(early_stopping_rounds, eval_metrics, eval_set.)\n",
    "# max_depth, learning_rate(학습률), 반복횟수 등 지정\n",
    "# 오류함수의 평가지표:logloss\n",
    "# 조기중단을 위한 최소 반복횟수는 150\n",
    "\n",
    "xgb_stop = XGBClassifier(n_estimators = 110, learning_rate = 0.1 , max_depth = 3)\n",
    "\n",
    "eval_df = [(df_train_x, df_train_y)]\n",
    "\n",
    "xgb_stop.fit(x_resampled, y_resampled, early_stopping_rounds = 150, \n",
    "                eval_metric=\"logloss\", eval_set = eval_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조기 중단 예측 및 모델 평가:Train  \n",
    "xgb_pred_stop = xgb_stop.predict(df_train_x)\n",
    "\n",
    "print('\\n 조기 중단 모델 평가 : Test \\n')\n",
    "eval_class_model(df_train_y, xgb_pred_stop)\n",
    "print('\\n',classification_report(df_train_y, xgb_pred_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.feature_importances_로 설명변수 중요도 확인 및 테이블로 저장\n",
    "df_importance = pd.DataFrame()\n",
    "df_importance[\"Feature\"] = v_feature_name\n",
    "df_importance[\"Importance\"] = xgb_stop.feature_importances_\n",
    "\n",
    "# df_feature_importance의 테이블을 중요도별로 정렬\n",
    "df_importance.sort_values(\"Importance\", ascending=False, inplace = True)\n",
    "df_temp = df_importance.round(3).head(6)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수 중요도 그래프\n",
    "# sort_values : 중요도가 높은 변수를 상위에 그림. \n",
    "df_temp.sort_values(\"Importance\", ascending=True, inplace = True)\n",
    "coordinates = range(len(df_temp))\n",
    "plt.barh(y = coordinates, width = df_temp[\"Importance\"])\n",
    "plt.yticks(coordinates, df_temp[\"Feature\"])\n",
    "plt.xlabel(\"설명변수 중요도\")\n",
    "plt.ylabel(\"설명변수\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486217b8",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d349312",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KNeighborsClassifier()\n",
    "\n",
    "# 구하고자 하는 parameter와 범위\n",
    "grid_params = {\n",
    "    'n_neighbors' : list(range(1,10)),\n",
    "    'weights' : [\"uniform\", \"distance\"],\n",
    "    'metric' : ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "# 정확도가 높은 최적 parameter 찾기\n",
    "grid_knn = GridSearchCV(estimator, grid_params, scoring=\"accuracy\", n_jobs = -1)\n",
    "grid_knn.fit(x_resampled, y_resampled)\n",
    "print(\"best estimator model: \\n{}\".format(grid_rf.best_estimator_))\n",
    "print(\"\\nbest parameter: \\n{}\".format(grid_rf.best_params_))\n",
    "print(\"\\nbest score: \\n{}\".format(grid_rf.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe67d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_knn.score(df_train_x, df_train_y))\n",
    "print(grid_knn.score(df_test_x, df_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6ecddc",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb2b1e6",
   "metadata": {},
   "source": [
    "#### 제발 얘도 범위 고려. 평생소원."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725182fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation 변경 \n",
    "para_function = [\"logistic\", \"tanh\", \"relu\"]\n",
    "# hidden_layer_sizes: 은닉층 변경 (20~240, by 30)\n",
    "para_hidden = [1 * hidden for hidden in range(148, 160)]\n",
    "# solver 변경 \n",
    "para_solver = [\"lbfgs\", \"sgd\", \"adam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f27993",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MLPClassifier(random_state=1234)\n",
    "# 구하고자 하는 parameter와 범위\n",
    "param_grid = {\"activation\": para_function,\n",
    "              \"hidden_layer_sizes\": para_hidden}\n",
    "# 정확도가 높은 최적 parameter 찾기\n",
    "grid_nn = GridSearchCV(estimator, param_grid, scoring=\"accuracy\", n_jobs = -1)\n",
    "grid_nn.fit(x_resampled, y_resampled)\n",
    "print(\"best estimator model: \\n{}\".format(grid_rf.best_estimator_))\n",
    "print(\"\\nbest parameter: \\n{}\".format(grid_rf.best_params_))\n",
    "print(\"\\nbest score: \\n{}\".format(grid_rf.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_nn.score(df_train_x, df_train_y))\n",
    "print(grid_nn.score(df_test_x, df_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c8b66",
   "metadata": {},
   "source": [
    "# 분석모델 그래프 대통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f56112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석 모델\n",
    "model = [\"Logistic\", \"DecisionTree\", \"RandomForest\", \"GradientBoosting\"\n",
    "         , \"XGBoosting\", \"K-NearestNEighbor\", \"NeuralNet\"]\n",
    "\n",
    "# 정확도 저장\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# auc score 저장\n",
    "model_auc = []\n",
    "\n",
    "# Precision, Recall score 저장\n",
    "model_precision = []; model_recall = []\n",
    "# f1 score 저장\n",
    "model_f1_score = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c23ef",
   "metadata": {},
   "source": [
    "## 아래 SCALE 종속변수 컬럼명으로 바꿔라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a577f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 정확도\n",
    "train_accuracy.append(accuracy_score(df_train[\"SCALE\"], y_pred_train_class))\n",
    "# test 정확도\n",
    "test_accuracy.append(accuracy_score(df_test[\"SCALE\"], y_pred_test_class))\n",
    "\n",
    "# 예측값\n",
    "y_pred = (y_pred_test > 0.53).astype(int)\n",
    "\n",
    "# roc_curve(실제값, 예측값), fpr = FP/(FP+TN): 거짓 양성 비율, tpr = TP/(TP+FN): 진짜 양성 비율(재현율)\n",
    "fpr, tpr, thresholds = roc_curve(df_test_y, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# auc 저장\n",
    "model_auc.append(roc_auc)\n",
    "\n",
    "# precision, recall score\n",
    "model_precision.append(precision_score(df_test_y, y_pred))\n",
    "model_recall.append(recall_score(df_test_y, y_pred))\n",
    "\n",
    "# f1 score\n",
    "model_f1_score.append(f1_score(df_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e580a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_final = DecisionTreeClassifier(max_depth=10\n",
    "                                           , min_samples_leaf=1\n",
    "                                           , min_samples_split=8, random_state= 1234)\n",
    "\n",
    "dt_final.fit(df_train_x, df_train_y)\n",
    "\n",
    "# train 정확도\n",
    "train_accuracy.append(dt_final.score(df_train_x, df_train_y))\n",
    "# test 정확도\n",
    "test_accuracy.append(dt_final.score(df_test_x, df_test_y))\n",
    "\n",
    "# 예측값\n",
    "y_pred = dt_final.predict(df_test_x)\n",
    "\n",
    "# roc_curve(실제값, 예측값), fpr = FP/(FP+TN): 거짓 양성 비율, tpr = TP/(TP+FN): 진짜 양성 비율(재현율)\n",
    "fpr, tpr, thresholds = roc_curve(df_test_y, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# auc 저장\n",
    "model_auc.append(roc_auc)\n",
    "\n",
    "# precision, recall score\n",
    "model_precision.append(precision_score(df_test_y, y_pred))\n",
    "model_recall.append(recall_score(df_test_y, y_pred))\n",
    "\n",
    "# f1 score\n",
    "model_f1_score.append(f1_score(df_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca954fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 정확도\n",
    "train_accuracy.append(grid_rf.score(df_train_x, df_train_y))\n",
    "# test 정확도\n",
    "test_accuracy.append(grid_rf.score(df_test_x, df_test_y))\n",
    "\n",
    "# 예측값\n",
    "y_pred = grid_rf.predict(df_test_x)\n",
    "\n",
    "# roc_curve(실제값, 예측값), fpr = FP/(FP+TN): 거짓 양성 비율, tpr = TP/(TP+FN): 진짜 양성 비율(재현율)\n",
    "fpr, tpr, thresholds = roc_curve(df_test_y, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# auc 저장\n",
    "model_auc.append(roc_auc)\n",
    "\n",
    "# precision, recall score\n",
    "model_precision.append(precision_score(df_test_y, y_pred))\n",
    "model_recall.append(recall_score(df_test_y, y_pred))\n",
    "\n",
    "# f1 score\n",
    "model_f1_score.append(f1_score(df_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 정확도\n",
    "train_accuracy.append(gb_final.score(df_train_x, df_train_y))\n",
    "# test 정확도\n",
    "test_accuracy.append(gb_final.score(df_test_x, df_test_y))\n",
    "\n",
    "# 예측값\n",
    "y_pred = gb_final.predict(df_test_x)\n",
    "\n",
    "# roc_curve(실제값, 예측값), fpr = FP/(FP+TN): 거짓 양성 비율, tpr = TP/(TP+FN): 진짜 양성 비율(재현율)\n",
    "fpr, tpr, thresholds = roc_curve(df_test_y, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# auc 저장\n",
    "model_auc.append(roc_auc)\n",
    "\n",
    "# precision, recall score\n",
    "model_precision.append(precision_score(df_test_y, y_pred))\n",
    "model_recall.append(recall_score(df_test_y, y_pred))\n",
    "\n",
    "# f1 score\n",
    "model_f1_score.append(f1_score(df_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c88779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 정확도\n",
    "train_accuracy.append(xgb_stop.score(df_train_x, df_train_y))\n",
    "# test 정확도\n",
    "test_accuracy.append(xgb_stop.score(df_test_x, df_test_y))\n",
    "\n",
    "# 예측값\n",
    "y_pred = xgb_stop.predict(df_test_x)\n",
    "\n",
    "# roc_curve(실제값, 예측값), fpr = FP/(FP+TN): 거짓 양성 비율, tpr = TP/(TP+FN): 진짜 양성 비율(재현율)\n",
    "fpr, tpr, thresholds = roc_curve(df_test_y, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# auc 저장\n",
    "model_auc.append(roc_auc)\n",
    "\n",
    "# precision, recall score\n",
    "model_precision.append(precision_score(df_test_y, y_pred))\n",
    "model_recall.append(recall_score(df_test_y, y_pred))\n",
    "\n",
    "# f1 score\n",
    "model_f1_score.append(f1_score(df_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 정확도\n",
    "train_accuracy.append(grid_knn.score(df_train_x, df_train_y))\n",
    "# test 정확도\n",
    "test_accuracy.append(grid_knn.score(df_test_x, df_test_y))\n",
    "\n",
    "# 예측값\n",
    "y_pred = grid_knn.predict(df_test_x)\n",
    "\n",
    "# roc_curve(실제값, 예측값), fpr = FP/(FP+TN): 거짓 양성 비율, tpr = TP/(TP+FN): 진짜 양성 비율(재현율)\n",
    "fpr, tpr, thresholds = roc_curve(df_test_y, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# auc 저장\n",
    "model_auc.append(roc_auc)\n",
    "\n",
    "# precision, recall score\n",
    "model_precision.append(precision_score(df_test_y, y_pred))\n",
    "model_recall.append(recall_score(df_test_y, y_pred))\n",
    "\n",
    "# f1 score\n",
    "model_f1_score.append(f1_score(df_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 정확도\n",
    "train_accuracy.append(nn_final.score(df_train_x, df_train_y))\n",
    "# test 정확도\n",
    "test_accuracy.append(nn_final.score(df_test_x, df_test_y))\n",
    "\n",
    "# 예측값\n",
    "y_pred = kk_final.predict(df_test_x)\n",
    "\n",
    "# roc_curve(실제값, 예측값), fpr = FP/(FP+TN): 거짓 양성 비율, tpr = TP/(TP+FN): 진짜 양성 비율(재현율)\n",
    "fpr, tpr, thresholds = roc_curve(df_test_y, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# auc 저장\n",
    "model_auc.append(roc_auc)\n",
    "\n",
    "# precision, recall score\n",
    "model_precision.append(precision_score(df_test_y, y_pred))\n",
    "model_recall.append(recall_score(df_test_y, y_pred))\n",
    "\n",
    "# f1 score\n",
    "model_f1_score.append(f1_score(df_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(index = model)\n",
    "df_eval['TrainAccuracy'] = train_accuracy ; df_eval['TestAccuracy'] = test_accuracy\n",
    "df_eval['AUC'] = model_auc\n",
    "df_eval['Precision'] = model_precision ; df_eval['Recall'] = model_recall\n",
    "df_eval['F1Score'] = model_f1_score\n",
    "df_eval.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a057a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별 평가 지표 확인\n",
    "df_eval.plot.bar(rot = 0, figsize=(10,6))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(axis = \"y\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
